Backend Architecture â€” AI Agent Lab API Layer
ğŸ¯ Objetivo
Exponer una API desacoplada y robusta para conectar el frontend del laboratorio con LangGraph y modelos LLM. Esta capa serÃ¡ responsable de:

Recibir prompts y parÃ¡metros desde el frontend

Ejecutar tareas usando el laboratorio (sin bloquear el backend)

Emitir eventos a WebSocket (progreso/output)

Persistir ejecuciones y logs en PostgreSQL

ğŸ§° Stack TecnolÃ³gico
FastAPI: Framework principal (ASGI-ready)

Redis: Pub/Sub entre backend y WebSocket

Node.js (opcional): WebSocket server independiente

PostgreSQL: Historial de ejecuciones y mÃ©tricas

Docker Compose: Entorno completo para despliegue local

ğŸ”— Flujo Principal
mermaid
Copiar
Editar
sequenceDiagram
  participant FE as Frontend
  participant API as FastAPI API
  participant LAB as LangGraph Lab (Python)
  participant REDIS as Redis PubSub
  participant WS as WebSocket Server

  FE->>API: POST /api/execute
  API->>LAB: Ejecutar prompt (background)
  LAB-->>REDIS: Emitir logs/output
  WS-->>FE: Reenviar vÃ­a socket
ğŸ›¡ï¸ Seguridad
CORS + validaciÃ³n con JWT o token

ValidaciÃ³n estricta (Pydantic)

Throttling por IP (middleware futuro)

Logging estructurado (por request ID)

ğŸ“ Estructura de Carpetas
bash
Copiar
Editar
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                  # Entrypoint FastAPI
â”‚   â”œâ”€â”€ api/                     # Endpoints REST
â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚       â”œâ”€â”€ routes/
â”‚   â”‚       â”‚   â””â”€â”€ execute.py   # POST /api/v1/execute
â”‚   â”‚       â”œâ”€â”€ schemas/
â”‚   â”‚       â”‚   â”œâ”€â”€ execution.py # Request/Response para ejecuciÃ³n
â”‚   â”‚       â”‚   â””â”€â”€ types.py     # FlowState, ExecutionMetrics, etc.
â”‚   â”œâ”€â”€ core/                    # ConfiguraciÃ³n y servicios globales
â”‚   â”‚   â”œâ”€â”€ config.py            # Lectura de .env, parÃ¡metros
â”‚   â”‚   â”œâ”€â”€ logger.py            # Logging con IDs de request
â”‚   â”‚   â””â”€â”€ redis.py             # Cliente de Redis (pub/sub)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ executor.py          # Invoca LangGraph o modelos locales
â”‚   â”œâ”€â”€ sockets/
â”‚   â”‚   â””â”€â”€ manager.py           # ConexiÃ³n con WS (opcional)
â”‚   â””â”€â”€ db/
â”‚       â””â”€â”€ models.py            # ORM/SQL para guardar resultados
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_execute.py          # Test unitario para POST /execute
â”œâ”€â”€ Dockerfile                   # Imagen base del backend
â””â”€â”€ docker-compose.yml           # Orquestador con Redis, Postgres, etc.
ğŸ“„ Detalles por MÃ³dulo
app/api/v1/routes/execute.py
Define el endpoint POST /api/v1/execute

Valida input con ExecutionRequest

Retorna ExecutionResult simulado (por ahora)

En futuro: delega a services.executor.run_execution

app/api/v1/schemas/
execution.py: Define el contrato ExecutionRequest, ExecutionResult

types.py: Define FlowState, NodeState, ExecutionMetrics, etc.

app/core/
config.py: Carga de .env, valores de entorno

logger.py: Inicializa loggers con IDs y timestamps

redis.py: Cliente para publicar eventos (publish_log, publish_output)

app/services/executor.py
Llama al LangGraph Lab local (via subprocess o import)

Simula ejecuciÃ³n en background (futuro: async def run con BackgroundTasks)

app/sockets/manager.py
Escucha eventos de Redis y emite por WebSocket

Puede ejecutarse como microservicio Node.js o Python

app/db/models.py
Define ORM (SQLAlchemy) para guardar ejecuciones pasadas

Clave para auditorÃ­a, historial, dashboards futuros

âœ… Buenas PrÃ¡cticas
MÃ³dulos desacoplados (api/core/services)

Tipos compartidos entre API y lÃ³gica de negocio (types.py)

Logs emitidos por Redis permiten multiconsumo (WS + auditorÃ­a)

Testeable desde el inicio (test_execute.py ya creado)

Documentado para escalar a mÃºltiples endpoints (/metrics, /history, /stream)